<!doctype html>
<!-- Generated from /Users/olofs_mba/Documents/Repos/CascadeProjects/windsurf-project/docs/runbooks/runbook-home-server.md — do not edit this file manually. -->
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Runbook: Home Server Operations (RUN-home-server)</title>
  <style>
    :root{
      --bg: #0b1020;
      --panel: #0f1730;
      --paper: #0e1430;
      --text: #e8ecff;
      --muted: #b8c0e6;
      --faint: #8a94c7;

      --border: rgba(232,236,255,0.12);
      --border-strong: rgba(232,236,255,0.18);
      --shadow: 0 12px 40px rgba(0,0,0,0.35);

      --accent: #6aa6ff;
      --accent-2: #8cf0d6;

      --ok: #27d17f;
      --warn: #ffcc66;
      --danger: #ff6b7a;
      --info: #7dd3fc;

      --code-bg: rgba(255,255,255,0.04);
      --code-border: rgba(255,255,255,0.10);

      --radius: 14px;
      --radius-sm: 10px;

      --maxw: 1000px;
    }

    /* Base */
    html, body { height: 100%; }
    body{
      margin:0;
      background:
        radial-gradient(1200px 700px at 15% 10%, rgba(106,166,255,0.22), transparent 60%),
        radial-gradient(900px 650px at 85% 0%, rgba(140,240,214,0.14), transparent 60%),
        linear-gradient(180deg, var(--bg), #050714 70%);
      color: var(--text);
      font: 16px/1.55 ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      letter-spacing: 0.1px;
      -webkit-font-smoothing: antialiased;
      -moz-osx-font-smoothing: grayscale;
    }

    a{
      color: var(--accent);
      text-decoration: none;
    }
    a:hover{ text-decoration: underline; }

    code, pre, kbd{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }

    .wrap{
      max-width: var(--maxw);
      margin: 42px auto;
      padding: 0 18px 70px;
    }

    .topbar{
      display:flex;
      align-items:flex-start;
      justify-content:space-between;
      gap: 18px;
      margin-bottom: 18px;
    }

    .brand{
      display:flex;
      flex-direction:column;
      gap: 8px;
    }

    .kicker{
      display:inline-block;
      font-size: 13px;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      color: var(--faint);
    }

    h1{
      margin: 0;
      font-size: 32px;
      letter-spacing: -0.02em;
      line-height: 1.1;
    }

    .subtitle{
      color: var(--muted);
      max-width: 60ch;
    }

    .badges{
      display:flex;
      flex-wrap:wrap;
      gap: 8px;
      justify-content:flex-end;
      margin-top: 2px;
    }

    .badge{
      border: 1px solid var(--border-strong);
      border-radius: 999px;
      padding: 6px 10px;
      font-size: 12px;
      color: var(--muted);
      background: rgba(255,255,255,0.03);
      white-space: nowrap;
    }
    .badge strong{ color: var(--text); font-weight: 600; }
    .badge.ok{ border-color: rgba(39,209,127,0.35); }
    .badge.warn{ border-color: rgba(255,204,102,0.35); }
    .badge.info{ border-color: rgba(125,211,252,0.35); }

    .panel{
      background: rgba(255,255,255,0.03);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      overflow:hidden;
    }

    .panel-inner{ padding: 16px 18px; }

    .meta{
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .meta-card{
      flex: 1 1 200px;
      min-width: 200px;
      background: rgba(255,255,255,0.02);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 12px 14px;
    }
    .meta-card h3{
      margin: 0 0 6px 0;
      font-size: 12px;
      color: var(--faint);
      text-transform: uppercase;
      letter-spacing: 0.12em;
    }
    .meta-card .value{
      color: var(--text);
      font-weight: 600;
    }
    .meta-card .value small{
      font-weight: 500;
      color: var(--muted);
    }

    .grid{
      display:grid;
      grid-template-columns: 240px 1fr;
      gap: 14px;
      padding: 16px 18px 18px;
    }

    .toc .panel-inner{ padding: 14px 14px; }
    .toc h2{
      margin: 0 0 8px 0;
      font-size: 13px;
      color: var(--faint);
      letter-spacing: 0.12em;
      text-transform: uppercase;
    }
    .toc ol{
      margin: 0;
      padding-left: 18px;
      color: var(--muted);
      font-size: 14px;
    }
    .toc li{ margin: 6px 0; }

    /* Content */
    main{ padding: 18px; }
    section{
      border-top: 1px solid var(--border);
      padding-top: 22px;
      margin-top: 18px;
    }
    section:first-child{
      border-top: none;
      padding-top: 0;
      margin-top: 0;
    }

    h2{
      margin: 0 0 10px 0;
      font-size: 22px;
      letter-spacing: -0.01em;
    }
    h3{
      margin: 18px 0 10px 0;
      font-size: 17px;
      letter-spacing: -0.01em;
      color: var(--text);
    }
    p{
      margin: 10px 0;
      color: var(--muted);
    }

    ul{
      margin: 10px 0 10px 18px;
      color: var(--muted);
    }
    li{ margin: 6px 0; }

    /* Code blocks */
    pre{
      margin: 10px 0 14px;
      padding: 14px 14px;
      background: var(--code-bg);
      border: 1px solid var(--code-border);
      border-radius: var(--radius-sm);
      overflow:auto;
      box-shadow: inset 0 1px 0 rgba(255,255,255,0.03);
    }
    pre code{
      color: var(--text);
      font-size: 13px;
      line-height: 1.5;
      display:block;
      white-space: pre;
    }
    code{
      color: var(--text);
      background: rgba(255,255,255,0.04);
      border: 1px solid rgba(255,255,255,0.06);
      padding: 1px 6px;
      border-radius: 8px;
      font-size: 0.95em;
    }

    /* Callouts */
    .callout{
      margin: 12px 0 14px;
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 12px 14px;
      background: rgba(255,255,255,0.02);
    }
    .callout .title{
      display:flex;
      align-items:center;
      gap: 10px;
      font-size: 13px;
      font-weight: 700;
      color: var(--text);
      text-transform: uppercase;
      letter-spacing: 0.12em;
    }
    .callout .title .dot{
      width: 10px;
      height: 10px;
      border-radius: 99px;
      background: var(--info);
      box-shadow: 0 0 0 3px rgba(125,211,252,0.12);
      flex: 0 0 auto;
    }
    .callout p{ margin: 6px 0; color: var(--muted); }
    .callout.note .title .dot{ background: var(--info); box-shadow: 0 0 0 3px rgba(125,211,252,0.12); }
    .callout.warn{ border-color: rgba(255,204,102,0.30); }
    .callout.warn .title .dot{ background: var(--warn); box-shadow: 0 0 0 3px rgba(255,204,102,0.12); }
    .callout.danger{ border-color: rgba(255,107,122,0.35); }
    .callout.danger .title .dot{ background: var(--danger); box-shadow: 0 0 0 3px rgba(255,107,122,0.12); }
    .callout.critical{ border-color: rgba(140,240,214,0.30); }
    .callout.critical .title .dot{ background: var(--accent-2); box-shadow: 0 0 0 3px rgba(140,240,214,0.12); }

    footer{
      margin-top: 24px;
      color: var(--faint);
      font-size: 13px;
      border-top: 1px solid var(--border);
      padding-top: 14px;
    }

    @media (max-width: 960px){
      .grid{ grid-template-columns: 1fr; }
      .badges{ justify-content:flex-start; }
    }
  </style>
</head>

<body>
  <div class="wrap">
    <div class="topbar">
      <div class="brand">
        <div class="kicker">Runbook</div>
        <h1>Home Server Operations</h1>
        <div class="subtitle">
          Operations guide for the home server hosting Skriptoteket and future HuleEdu services.
        </div>
      </div>
      <div class="badges" aria-label="document metadata badges">
        <div class="badge ok"><strong>Status:</strong> Active</div>
        <div class="badge info"><strong>System:</strong> hemma.hule.education</div>
        <div class="badge"><strong>ID:</strong> RUN-home-server</div>
      </div>
    </div>

    <div class="panel">
      <div class="panel-inner">
        <div class="meta" aria-label="document metadata">
          <div class="meta-card">
            <h3>Owners</h3>
            <div class="value">olof</div>
          </div>
          <div class="meta-card">
            <h3>Lifecycle</h3>
            <div class="value">
              Created <small>2025-12-16</small><br />
              Updated <small>2026-01-12</small>
            </div>
          </div>
        </div>
      </div>

      <div class="grid">
        <aside class="toc">
          <div class="panel">
            <div class="panel-inner">
              <h2>Contents</h2>
              <ol>
                <li><a href="#setup">Setup</a></li>
                <li><a href="#daily-ops">Daily Ops</a></li>
                <li><a href="#deploy">Deploy</a></li>
                <li><a href="#data">Data</a></li>
                <li><a href="#observability">Observability</a></li>
                <li><a href="#troubleshooting">Troubleshooting</a></li>
              </ol>
            </div>
          </div>
        </aside>

        <main>
          <section id="setup">
            <h2>Setup</h2>
<h3 id="server-access-ssh">Server Access (SSH)</h3>
<pre><code class="language-bash"># Remote admin access (VPN-gated; Tailscale)
ssh hemma           # paunchygent (non-root default)
ssh hemma-root      # root (use only with explicit approval)

# Local network break-glass (LAN)
ssh hemma-local
ssh hemma-local-root
</code></pre>
<div class="callout note">
  <div class="title"><span class="dot"></span>Notes</div>
<ul>
<li>SSH is intentionally <strong>not exposed on the public internet</strong> (no router port-forward for <code>22/tcp</code>).</li>
<li>Default user is non-root (<code>paunchygent</code>); use <code>ssh hemma-root</code> only with explicit approval.</li>
<li>UFW allows SSH only:</li>
<li>On <code>tailscale0</code> (VPN), and</li>
<li>From the LAN break-glass subnet <code>192.168.0.0/24</code>.</li>
<li>If <code>ssh hemma</code> still points at <code>hemma.hule.education</code>, update your <code>~/.ssh/config</code> so <code>ssh hemma</code> uses MagicDNS:</li>
</ul>
</div>
<pre><code class="language-text">Host hemma
  HostName hemma.tail730aa2.ts.net
  User paunchygent
  IdentityFile ~/.ssh/hemma-paunchygent_ed25519

Host hemma-root
  HostName hemma.tail730aa2.ts.net
  User root

Host hemma-local
  HostName 192.168.0.9
  User paunchygent
  IdentityFile ~/.ssh/hemma-paunchygent_ed25519

Host hemma-local-root
  HostName 192.168.0.9
  User root
</code></pre>
<h3 id="ssh-hardening-fail2ban">SSH Hardening + Fail2ban</h3>
<p>Security hardening (sshd settings, Fail2ban jails, nginx-proxy probe jail) is documented in
<a href="../reference/ref-home-server-security-hardening.md">ref-home-server-security-hardening.md</a>.</p>
<h3 id="sshnetwork-watchdog-active-remediation">SSH/Network Watchdog (Active Remediation)</h3>
<p>Runs every 2 minutes and remediates SSH/network drift. It restarts <code>systemd-networkd</code>,
<code>systemd-resolved</code>, and <code>tailscaled</code> if route/ping checks fail, and reboots after 3
consecutive failures.</p>
<p>Script: <code>/usr/local/bin/ssh-watchdog.sh</code></p>
<pre><code class="language-bash">sudo systemctl status ssh-watchdog.timer --no-pager
sudo journalctl -t ssh-watchdog --since &quot;1 hour ago&quot;
sudo systemctl disable --now ssh-watchdog.timer
</code></pre>
<h3 id="heartbeat-log-hang-correlation">Heartbeat Log (Hang Correlation)</h3>
<p>Logs a simple heartbeat every minute to make hang windows obvious.</p>
<pre><code class="language-bash">sudo systemctl status heartbeat-log.timer --no-pager
sudo journalctl -t heartbeat --since &quot;2 hours ago&quot;
</code></pre>
<h3 id="current-network-ddns-settings-as-of-2026-01-02">Current Network + DDNS Settings (as of 2026-01-02)</h3>
<pre><code class="language-text"># Network (ethernet only; Wi‑Fi disabled)
/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg
  network: {config: disabled}

/etc/netplan/01-netcfg.yaml
  enp7s0: dhcp4=true, dhcp6=false, optional=true

/etc/netplan/50-cloud-init.yaml.disabled
/etc/netplan/50-cloud-init.yaml.bak

systemctl status wpa_supplicant@wlp5s0.service -&gt; inactive (disabled)
</code></pre>
<pre><code class="language-text"># DDNS (Namecheap)
systemctl status ddclient -&gt; active
/etc/ddclient.conf
  protocol=namecheap
  server=dynamicdns.park-your-domain.com
  login=hule.education
  host=hemma
</code></pre>
<h3 id="gpu-tunnels-local-workstation">GPU Tunnels (local workstation)</h3>
<p>Use the local helper script to tunnel GPU services to localhost:</p>
<pre><code class="language-bash">~/bin/hemma-gpu-tunnel start        # start llama + tabby tunnels
~/bin/hemma-gpu-tunnel start-llama  # start only llama tunnel (:8082)
~/bin/hemma-gpu-tunnel start-tabby  # start only tabby tunnel (:8083)
~/bin/hemma-gpu-tunnel stop         # stop both tunnels
~/bin/hemma-gpu-tunnel stop-llama   # stop only llama tunnel (:8082)
~/bin/hemma-gpu-tunnel stop-tabby   # stop only tabby tunnel (:8083)
~/bin/hemma-gpu-tunnel status       # show tunnel status
</code></pre>
<h3 id="host-gpu-ai-services-systemd">Host GPU AI Services (systemd)</h3>
<p>On <code>hemma</code>, the AI services run on the host (not in Docker) as systemd units:</p>
<ul>
<li>llama.cpp server (one of):</li>
<li><code>llama-server-vulkan.service</code> (Vulkan backend, port <code>8082</code>)</li>
<li><code>llama-server-hip.service</code> (ROCm/HIP backend, port <code>8082</code>)</li>
<li><code>tabby.service</code> (Tabby completion proxy, port <code>8083</code>)</li>
</ul>
<p>Only one llama.cpp service should be enabled at a time (both bind <code>:8082</code>).</p>
<p>Canonical runbooks:</p>
<ul>
<li><code>docs/runbooks/runbook-tabby-codemirror.md</code> (llama-server + Tabby ops)</li>
<li><code>docs/runbooks/runbook-gpu-ai-workloads.md</code> (GPU/ROCm ops + HIP/Vulkan switching)</li>
</ul>
<p>Quick checks:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo systemctl status --no-pager llama-server-hip.service llama-server-vulkan.service tabby.service | head -n 60&quot;
ssh hemma &quot;curl -s http://127.0.0.1:8082/health&quot;
ssh hemma &quot;curl -s http://127.0.0.1:8083/v1/health&quot;
</code></pre>
<h3 id="amdgpu-release-watch-hemma">AMDGPU Release Watch (hemma)</h3>
<p>Daily check for new AMDGPU releases (alerts when 30.30.x or Radeon Software 25.40 notes appear).</p>
<pre><code class="language-bash"># Run once
ssh hemma &quot;sudo systemctl start amdgpu-release-watch.service&quot;

# Status + logs
ssh hemma &quot;sudo systemctl status --no-pager amdgpu-release-watch.timer&quot;
ssh hemma &quot;sudo journalctl -t amdgpu-release-watch --since '7 days ago' --no-pager&quot;
</code></pre>
<p>Files:</p>
<ul>
<li>Script: <code>/usr/local/bin/amdgpu-release-watch.sh</code></li>
<li>Unit: <code>/etc/systemd/system/amdgpu-release-watch.service</code></li>
<li>Timer: <code>/etc/systemd/system/amdgpu-release-watch.timer</code></li>
</ul>
<h3 id="host-logs-disk-health-hemma">Host Logs + Disk Health (hemma)</h3>
<p>Log paths (root):</p>
<ul>
<li><code>/root/logs/incident-YYYYMMDD-HHMMSS-HHMMSS.log</code> (incident windows)</li>
<li><code>/root/logs/smart/</code> (SMART snapshots)</li>
<li><code>/sys/fs/pstore</code> (kernel crash logs; empty until a crash occurs)</li>
<li><code>/var/lib/systemd/pstore</code> (archived pstore logs via systemd-pstore)</li>
</ul>
<p>pstore notes:</p>
<ul>
<li>Backend: <code>efi_pstore</code> (loaded via <code>/etc/modules-load.d/pstore.conf</code>).</li>
<li>Service: <code>systemd-pstore.service</code> (archives pstore files into
  <code>/var/lib/systemd/pstore</code>).</li>
<li>An empty directory is normal before the first crash.</li>
</ul>
<p>Quick checks:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo ls -la /sys/fs/pstore&quot;
ssh hemma &quot;sudo ls -la /var/lib/systemd/pstore&quot;
ssh hemma &quot;sudo systemctl status --no-pager systemd-pstore&quot;
</code></pre>
<h3 id="crash-capture-hardening-hemma-2026-01-07">Crash Capture Hardening (hemma, 2026-01-07)</h3>
<p>Crash capture is hardened with larger kernel buffers, panic-on-oops, kdump, and netconsole.</p>
<p>Kernel/sysctl settings:</p>
<ul>
<li>Sysctl config: <code>/etc/sysctl.d/99-crash-capture.conf</code></li>
<li><code>kernel.panic_on_oops=1</code></li>
<li><code>kernel.panic=10</code></li>
<li><code>kernel.softlockup_panic=1</code></li>
<li><code>kernel.panic_on_warn=1</code></li>
<li>GRUB cmdline: <code>log_buf_len=4M</code></li>
<li>GPU hang mitigation flags (GRUB cmdline, hemma):</li>
<li><code>amdgpu.cwsr_enable=0</code></li>
<li><code>amdgpu.mcbp=0</code></li>
<li><code>amdgpu.runpm=0</code></li>
<li>Crash-kernel GPU blacklist (prevents kdump hang if AMDGPU is wedged):</li>
<li><code>KDUMP_CMDLINE_APPEND="... modprobe.blacklist=amdgpu"</code> in <code>/etc/default/kdump-tools</code></li>
<li>Reload kdump kernel after changes: <code>sudo kdump-config unload &amp;&amp; sudo kdump-config load</code></li>
<li>Verify: <code>sudo kdump-config show</code> (kexec cmdline should include <code>modprobe.blacklist=amdgpu</code>)</li>
<li>Kdump enabled via <code>linux-crashdump</code> + <code>kdump-tools</code></li>
<li><code>crashkernel=1536M</code> set in <code>/etc/default/grub.d/kdump-tools.cfg</code> (requires <code>update-grub</code> + reboot)</li>
<li>Reduced kdump dumps enabled: <code>MAKEDUMP_ARGS="-c -d 31"</code> in <code>/etc/default/kdump-tools</code></li>
<li>Faster + smaller kernel-only dumps; user-space cores handled by <code>systemd-coredump</code></li>
<li>Savecore timeout guard: <code>KDUMP_SAVECORE_TIMEOUT=40s</code> in <code>/etc/default/kdump-tools</code></li>
<li>The kdump savecore wrapper uses <code>timeout --preserve-status</code> when set (prevents infinite hang)</li>
<li>Post-kdump reboot hardening (avoid hanging <code>systemctl reboot</code> path):</li>
<li>Unit override: <code>/etc/systemd/system/kdump-tools-dump.service.d/10-sysrq-reboot.conf</code></li>
<li>Wrapper: <code>/usr/local/sbin/kdump-savecore-and-sysrq-reboot</code><ul>
<li>Runs <code>kdump-config savecore</code> (with <code>KDUMP_SAVECORE_TIMEOUT</code>)</li>
<li>Forces reboot via SysRq: <code>echo b &gt; /proc/sysrq-trigger</code> (falls back to <code>reboot -f</code> if needed)</li>
</ul>
</li>
<li>Hardware watchdog (hard reset if the host wedges, including crash-kernel hang):</li>
<li>Driver: <code>sp5100_tco</code> (SP5100/SB800 TCO watchdog)</li>
<li>Module loader (explicit, because <code>systemd-modules-load</code> deny-lists this driver via kmod): <code>/etc/systemd/system/sp5100-tco-watchdog.service</code></li>
<li>systemd watchdog config: <code>/etc/systemd/system.conf.d/99-watchdog.conf</code><ul>
<li><code>RuntimeWatchdogSec=3min</code> (plus reboot/shutdown watchdog at 3min)</li>
</ul>
</li>
<li>Verify watchdog is active:<ul>
<li><code>systemctl show -p WatchdogDevice -p RuntimeWatchdogUSec</code></li>
<li><code>sudo journalctl -b --no-pager | rg -i 'Using hardware watchdog|Watchdog running'</code></li>
</ul>
</li>
<li>Controlled crash testing (maintenance window only):</li>
<li>Trigger: <code>ssh hemma "sudo sh -c 'echo 1 &gt; /proc/sys/kernel/sysrq; echo c &gt; /proc/sysrq-trigger'"</code></li>
<li>Verify dump + crash boot:<ul>
<li><code>ssh hemma "journalctl --list-boots | tail -n 10"</code></li>
<li><code>ssh hemma "sudo journalctl -b -1 -u kdump-tools-dump.service --no-pager | tail -n 200"</code></li>
<li><code>ssh hemma "ls -lah /var/crash | tail -n 20"</code></li>
</ul>
</li>
<li>If it was a test, rename the dump directory to <code>*-test</code> to avoid confusion.</li>
</ul>
<p>One-time DC-off test boot (headless):</p>
<ul>
<li>Add custom entries in <code>/etc/grub.d/40_custom</code> for <code>Ubuntu (safe)</code> and <code>Ubuntu (dc=0 test)</code>.</li>
<li>Regenerate GRUB: <code>sudo update-grub</code>.</li>
<li>One-time boot: <code>sudo grub-reboot "Ubuntu (dc=0 test)" &amp;&amp; sudo reboot</code>.</li>
<li>Verify after boot: <code>cat /proc/cmdline | rg amdgpu.dc=0</code>.</li>
<li>Expect display corruption/blank after early boot; use SSH. A normal reboot returns to the safe entry.</li>
<li>Related reference: <code>docs/reference/reports/ref-hemma-kdump-amdgpu-blacklist-dc0-test-2026-01-11.md</code>.</li>
</ul>
<p>Netconsole (UDP kernel logging):</p>
<ul>
<li>Module config: <code>/etc/modprobe.d/netconsole.conf</code></li>
<li>Module load: <code>/etc/modules-load.d/netconsole.conf</code></li>
<li>Current target: <code>192.168.0.11:6666</code> (listener on Mac; update if the receiver changes)</li>
<li>Verify sender:</li>
</ul>
<pre><code class="language-bash">ssh hemma &quot;dmesg -T | rg -i 'netconsole|netpoll' | tail -n 20&quot;
</code></pre>
<p>Listener (Mac):</p>
<pre><code class="language-bash">sudo tcpdump -ni en0 udp port 6666
</code></pre>
<p>Reboot log retrieval (persistent journal):</p>
<pre><code class="language-bash"># Boot timeline
ssh hemma &quot;journalctl --list-boots | tail -n 10&quot;

# Current and previous boot logs
ssh hemma &quot;journalctl -b 0 --no-pager&quot;
ssh hemma &quot;journalctl -b -1 --no-pager&quot;
</code></pre>
<p>SMART monitoring:</p>
<ul>
<li>Service: <code>smartmontools.service</code></li>
<li>Config: <code>/etc/smartd.conf</code></li>
</ul>
<p>Cleanup (30-day retention):</p>
<ul>
<li>Script: <code>/usr/local/bin/cleanup-smart-logs.sh</code></li>
<li>Timer: <code>cleanup-smart-logs.timer</code></li>
</ul>
<h3 id="repo-compose-layout-production">Repo + Compose Layout (Production)</h3>
<ul>
<li>App repo: <code>~/apps/skriptoteket/</code></li>
<li>Production compose: <code>compose.prod.yaml</code> (uses <code>shared-postgres</code> on <code>hule-network</code>)</li>
<li>Observability stack: <code>compose.observability.yaml</code></li>
<li>Development compose: <code>compose.yaml</code> (local postgres only)</li>
</ul>
<div class="callout critical">
  <div class="title"><span class="dot"></span>Critical</div>
<p>Production uses <code>compose.prod.yaml</code>, NOT <code>compose.yaml</code>.</p>
</div>
<p>Recommended CLI tools + install steps: see <a href="../reference/ref-home-server-cli-tools.md">ref-home-server-cli-tools.md</a>.</p>
<h3 id="command-patterns-use-these">Command Patterns (Use These)</h3>
<pre><code class="language-bash"># 1) Compose commands (from repo root)
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml &lt;command&gt;&quot;

# 2) Run CLI inside web container (compose)
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec -T -e PYTHONPATH=/app/src web pdm run python -m skriptoteket.cli &lt;command&gt;&quot;

# 3) Direct docker exec (used by systemd timers)
ssh hemma &quot;/snap/bin/docker exec -e PYTHONPATH=/app/src skriptoteket-web pdm run python -m skriptoteket.cli &lt;command&gt;&quot;
</code></pre>
<p>Architecture overview diagram: see <a href="../reference/ref-home-server-architecture.md">ref-home-server-architecture.md</a>.</p>
<h3 id="nginx-proxy-service-routing-hardening">nginx-proxy (service routing + hardening)</h3>
<p>Details for adding new services and edge hardening live in
<a href="../reference/ref-home-server-nginx-proxy.md">ref-home-server-nginx-proxy.md</a>.</p>
          </section>

          <section id="daily-ops">
            <h2>Daily Ops</h2>
<h3 id="quick-status-check">Quick Status Check</h3>
<pre><code class="language-bash"># All containers
ssh hemma &quot;sudo docker ps&quot;

# Skriptoteket + core services
ssh hemma &quot;sudo docker ps | grep -E 'skriptoteket|nginx|postgres'&quot;
</code></pre>
<h3 id="view-logs">View Logs</h3>
<pre><code class="language-bash"># Web application logs
ssh hemma &quot;sudo docker logs -f skriptoteket-web&quot;

# Nginx access logs
ssh hemma &quot;sudo docker logs -f nginx-proxy&quot;

# Database logs (check for query errors)
ssh hemma &quot;sudo docker logs -f shared-postgres&quot;
</code></pre>
<p>Structured logs + correlation IDs: see <a href="runbook-observability-logging.md">runbook-observability-logging.md</a>.</p>
<h3 id="restart-services">Restart Services</h3>
<pre><code class="language-bash"># Restart Skriptoteket (preserves network connections)
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml restart&quot;

# Restart observability stack
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.observability.yaml restart&quot;

# nginx-proxy auto-reloads when containers change (no manual reload needed)
</code></pre>
<div class="callout warn">
  <div class="title"><span class="dot"></span>Note</div>
<p><code>docker compose restart</code> does <strong>not</strong> re-read <code>.env</code>. For env var changes use a recreate:</p>
</div>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml up -d --no-deps --force-recreate web&quot;
</code></pre>
<h3 id="disk-space-session-cleanup">Disk Space / Session Cleanup</h3>
<p>Session files are stored in <code>ARTIFACTS_ROOT/sessions/</code> (prod: <code>/app/.artifacts/sessions/</code>). An hourly systemd timer
runs TTL cleanup automatically.</p>
<pre><code class="language-bash"># Check timer status
ssh hemma &quot;sudo systemctl list-timers | grep skriptoteket&quot;

# View cleanup logs
ssh hemma &quot;sudo journalctl -u skriptoteket-session-files-cleanup.service -n 50 --no-pager&quot;

# Manual trigger (if needed)
ssh hemma &quot;sudo systemctl start skriptoteket-session-files-cleanup.service&quot;
</code></pre>
<p>Manual cleanup commands:</p>
<pre><code class="language-bash"># TTL-based cleanup (same as timer runs)
ssh hemma &quot;/snap/bin/docker exec -e PYTHONPATH=/app/src skriptoteket-web pdm run python -m skriptoteket.cli cleanup-session-files&quot;

# DANGER: Delete ALL session files (requires --yes)
ssh hemma &quot;/snap/bin/docker exec -e PYTHONPATH=/app/src skriptoteket-web pdm run python -m skriptoteket.cli clear-all-session-files --yes&quot;
</code></pre>
<h3 id="platform-only-llm-debug-captures-option-a">Platform-only LLM debug captures (Option A)</h3>
<p>When enabled, Skriptoteket persists <strong>sensitive</strong> debug captures for edit-ops generation and preview failures under the
artifacts volume.</p>
<ul>
<li>Config: <code>LLM_CAPTURE_ON_ERROR_ENABLED=true</code> (default: <code>false</code>)</li>
<li>Capture id: the request correlation id (<code>X-Correlation-ID</code> / <code>correlation_id</code>)</li>
<li>Location (prod): <code>/app/.artifacts/llm-captures/&lt;kind&gt;/&lt;capture_id&gt;/capture.json</code></li>
<li>Security: captures may include tool code and raw model output; access is platform-only (filesystem/SSH).</li>
</ul>
<p>List recent captures:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo docker exec skriptoteket-web ls -1 /app/.artifacts/llm-captures 2&gt;/dev/null || true&quot;
</code></pre>
<p>Open a specific capture (replace <code>&lt;CID&gt;</code>):</p>
<pre><code class="language-bash">ssh hemma \&quot;sudo docker exec -T skriptoteket-web sh -lc 'cat /app/.artifacts/llm-captures/chat_ops_response/&lt;CID&gt;/capture.json | jq .'\&quot;
</code></pre>
<h3 id="sandbox-snapshot-cleanup-db">Sandbox Snapshot Cleanup (DB)</h3>
<p>Sandbox preview snapshots are stored in PostgreSQL with a TTL (24h). Cleanup is scheduled server-side via systemd.</p>
<p>Unit file definitions are in <a href="../reference/ref-home-server-cleanup-timers.md">ref-home-server-cleanup-timers.md</a> (or inspect on host with
<code>sudo systemctl cat skriptoteket-sandbox-snapshots-cleanup.service</code>).</p>
<p>Enable and verify:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo systemctl daemon-reload&quot;
ssh hemma &quot;sudo systemctl enable --now skriptoteket-sandbox-snapshots-cleanup.timer&quot;
ssh hemma &quot;sudo systemctl list-timers | grep skriptoteket-sandbox-snapshots&quot;
ssh hemma &quot;sudo journalctl -u skriptoteket-sandbox-snapshots-cleanup.service -n 50 --no-pager&quot;
</code></pre>
<div class="callout note">
  <div class="title"><span class="dot"></span>Live note (hemma)</div>
<p>timer is enabled and runs hourly; see <code>systemctl status skriptoteket-sandbox-snapshots-cleanup.timer</code>.</p>
</div>
<p>Manual trigger:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo systemctl start skriptoteket-sandbox-snapshots-cleanup.service&quot;
</code></pre>
<h3 id="login-events-cleanup-db">Login Events Cleanup (DB)</h3>
<p>Login event audit rows are retained for 90 days. Cleanup is scheduled server-side via systemd.</p>
<p>Unit file definitions are in <a href="../reference/ref-home-server-cleanup-timers.md">ref-home-server-cleanup-timers.md</a> (or inspect on host with
<code>sudo systemctl cat skriptoteket-login-events-cleanup.service</code>).</p>
<p>Enable and verify:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo systemctl daemon-reload&quot;
ssh hemma &quot;sudo systemctl enable --now skriptoteket-login-events-cleanup.timer&quot;
ssh hemma &quot;sudo systemctl list-timers | grep skriptoteket-login-events&quot;
ssh hemma &quot;sudo journalctl -u skriptoteket-login-events-cleanup.service -n 50 --no-pager&quot;
</code></pre>
<p>Manual trigger:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo systemctl start skriptoteket-login-events-cleanup.service&quot;
</code></pre>
<h3 id="ssl-certificate">SSL Certificate</h3>
<p>Check expiry:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo docker exec nginx-proxy cat /etc/nginx/certs/live/skriptoteket.hule.education/fullchain.pem | openssl x509 -noout -dates&quot;
</code></pre>
<p>Renew:</p>
<pre><code class="language-bash">ssh hemma &quot;cd ~/infrastructure &amp;&amp; sudo docker compose run --rm certbot renew&quot;
ssh hemma &quot;sudo docker exec nginx-proxy nginx -s reload&quot;
</code></pre>
          </section>

          <section id="deploy">
            <h2>Deploy</h2>
<h3 id="standard-deploy-code-changes">Standard Deploy (Code Changes)</h3>
<pre><code class="language-bash"># Build runner image (required for tool/editor sandbox runs)
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; git pull &amp;&amp; sudo docker compose -f compose.prod.yaml --profile build-only build runner&quot;

# Deploy web (app container)
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml up -d --build&quot;
</code></pre>
<p>If migrations are needed:</p>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec web pdm run db-upgrade&quot;
</code></pre>
<h3 id="deploy-with-force-recreate">Deploy with Force Recreate</h3>
<p>Use when <code>compose.prod.yaml</code> changes (networks, volumes, environment).</p>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml up -d --force-recreate&quot;
</code></pre>
<h3 id="rollback">Rollback</h3>
<pre><code class="language-bash"># Check available commits
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; git log --oneline -10&quot;

# Checkout previous version
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; git checkout &lt;commit-hash&gt;&quot;

# Rebuild and restart
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml up -d --build&quot;
</code></pre>
          </section>

          <section id="data">
            <h2>Data</h2>
<p>Production uses <code>shared-postgres</code> (external container on <code>hule-network</code>).</p>
<h3 id="connect-to-database">Connect to Database</h3>
<pre><code class="language-bash">ssh hemma &quot;sudo docker exec -it shared-postgres psql -U postgres -d skriptoteket&quot;
</code></pre>
<h3 id="backup-database">Backup Database</h3>
<pre><code class="language-bash">ssh hemma &quot;sudo docker exec shared-postgres pg_dump -U postgres skriptoteket &gt; ~/backups/skriptoteket-\$(date +%Y%m%d).sql&quot;
</code></pre>
<h3 id="restore-database">Restore Database</h3>
<pre><code class="language-bash">ssh hemma &quot;sudo docker exec -i shared-postgres psql -U postgres -d skriptoteket &lt; ~/backups/skriptoteket-YYYYMMDD.sql&quot;
</code></pre>
<h3 id="run-migrations">Run Migrations</h3>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec web pdm run db-upgrade&quot;
</code></pre>
<h3 id="full-database-reset-danger">Full Database Reset (DANGER)</h3>
<p>This destroys all data. Only use for fresh installations. <code>shared-postgres</code> is external and not managed by this compose.</p>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml down&quot;

# Connect to shared-postgres and drop/recreate database
ssh hemma &quot;sudo docker exec -it shared-postgres psql -U postgres -c 'DROP DATABASE IF EXISTS skriptoteket;'&quot;
ssh hemma &quot;sudo docker exec -it shared-postgres psql -U postgres -c 'CREATE DATABASE skriptoteket;'&quot;

# Restart and run migrations
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml up -d&quot;
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec web pdm run db-upgrade&quot;
</code></pre>
<p>Then follow:</p>
<ul>
<li><a href="runbook-user-management.md">runbook-user-management.md</a> (bootstrap superuser / provision)</li>
<li><a href="runbook-script-bank-seeding-home-server.md">runbook-script-bank-seeding-home-server.md</a> (seed script bank)</li>
</ul>
<h3 id="user-management">User Management</h3>
<p>See <a href="runbook-user-management.md">runbook-user-management.md</a> for details.</p>
<h3 id="script-bank-seeding">Script Bank Seeding</h3>
<p>See <a href="runbook-script-bank-seeding-home-server.md">runbook-script-bank-seeding-home-server.md</a>.</p>
          </section>

          <section id="observability">
            <h2>Observability</h2>
<p>Observability operations are documented in the dedicated runbooks:</p>
<ul>
<li>Overview + access: <code>docs/runbooks/runbook-observability.md</code></li>
<li>Logs: <code>docs/runbooks/runbook-observability-logging.md</code></li>
<li>Metrics: <code>docs/runbooks/runbook-observability-metrics.md</code></li>
<li>Tracing: <code>docs/runbooks/runbook-observability-tracing.md</code></li>
</ul>
          </section>

          <section id="troubleshooting">
            <h2>Troubleshooting</h2>
<h3 id="ssh-unreachable-after-reboot">SSH Unreachable After Reboot</h3>
<p><strong>Symptom</strong>: <code>ssh hemma</code> times out even though the server is powered on.</p>
<p><strong>Common cause</strong>: Network instability or DHCP churn (Wi‑Fi flapping / multiple default routes).</p>
<p><strong>Fix</strong>:</p>
<pre><code class="language-bash"># Server should use ethernet only; Wi‑Fi disabled via netplan override.
# Confirm on the server:
ssh hemma &quot;ip -4 addr show enp7s0&quot;
ssh hemma &quot;ip route | head -n 5&quot;

# If needed, check watchdog + heartbeat logs for evidence:
ssh hemma &quot;sudo journalctl -t ssh-watchdog --since '2 hours ago'&quot;
ssh hemma &quot;sudo journalctl -t heartbeat --since '2 hours ago'&quot;

# Incident log captures (if taken):
ssh hemma &quot;sudo ls -1 /root/logs/incident-*.log | tail -n 5&quot;
</code></pre>
<h3 id="incident-log-capture-periodic">Incident Log Capture (Periodic)</h3>
<p>Skriptoteket runs a lightweight periodic capture to preserve the last few minutes of logs plus GPU state.</p>
<ul>
<li>Script: <code>/usr/local/bin/skriptoteket-incident-capture.sh</code></li>
<li>Logs: <code>/root/logs/incident-*.log</code></li>
<li>Systemd: <code>skriptoteket-incident-capture.service</code> + <code>skriptoteket-incident-capture.timer</code></li>
<li>Defaults: every 5 minutes, 10-minute window, 7-day retention</li>
<li>Includes: system + kernel logs, llama/tabby service logs, GPU runtime state, <code>rocm-smi</code> power/temps/clocks, and
  <code>/sys/class/hwmon</code> snapshot (uses <code>sensors</code> if installed).</li>
<li>Alert thresholds (override via env): <code>INCIDENT_GPU_EDGE_WARN_C</code>, <code>INCIDENT_GPU_JUNCTION_WARN_C</code>,
  <code>INCIDENT_GPU_MEM_WARN_C</code>, <code>INCIDENT_GPU_PPT_WARN_W</code>, <code>INCIDENT_CPU_TCTL_WARN_C</code>.</li>
</ul>
<p>Check status:</p>
<pre><code class="language-bash">ssh hemma &quot;sudo systemctl status --no-pager skriptoteket-incident-capture.timer&quot;
ssh hemma &quot;sudo ls -1 /root/logs/incident-*.log | tail -n 5&quot;
</code></pre>
<h3 id="502-bad-gateway">502 Bad Gateway</h3>
<p><strong>Symptom</strong>: nginx returns 502 after container restart.</p>
<p><strong>Cause</strong>: Web container not connected to <code>hule-network</code>.</p>
<p><strong>Fix</strong>:</p>
<pre><code class="language-bash"># Verify network membership
ssh hemma &quot;sudo docker network inspect hule-network --format '{{json .Containers}}' | python3 -m json.tool | grep skriptoteket&quot;

# If missing, reconnect manually (temporary fix)
ssh hemma &quot;sudo docker network connect hule-network skriptoteket-web&quot;

# Permanent fix: redeploy with compose.prod.yaml
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml up -d --force-recreate&quot;
</code></pre>
<h3 id="307-redirect-to-http-instead-of-https">307 Redirect to HTTP Instead of HTTPS</h3>
<p><strong>Symptom</strong>: Clicking links redirects to <code>http://</code> URL, breaking the site.</p>
<p><strong>Cause</strong>: Uvicorn doesn't know original scheme was HTTPS.</p>
<p><strong>Fix</strong>: Ensure <code>pyproject.toml</code> serve command includes proxy headers:</p>
<pre><code class="language-toml">serve = &quot;uvicorn ... --proxy-headers --forwarded-allow-ips='*'&quot;
</code></pre>
<p>And nginx sets the header:</p>
<pre><code class="language-nginx">proxy_set_header X-Forwarded-Proto $scheme;
</code></pre>
<h3 id="500-internal-server-error-on-all-routes">500 Internal Server Error on All Routes</h3>
<p><strong>Symptom</strong>: Every page returns 500 error.</p>
<p><strong>Cause</strong>: Usually database tables missing (migrations not run).</p>
<p><strong>Diagnosis</strong>:</p>
<pre><code class="language-bash"># Check web container logs for &quot;relation does not exist&quot; errors
ssh hemma &quot;sudo docker logs skriptoteket-web --tail 50&quot;
</code></pre>
<p><strong>Fix</strong>:</p>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec web pdm run db-upgrade&quot;
</code></pre>
<h3 id="cli-commands-fail-with-no-module-named-skriptoteket">CLI Commands Fail with "No module named 'skriptoteket'"</h3>
<p><strong>Cause</strong>: PYTHONPATH not set for PEP 582 mode.</p>
<p><strong>Fix</strong>: Always include <code>-e PYTHONPATH=/app/src</code> when running CLI commands:</p>
<pre><code class="language-bash">ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec -T -e PYTHONPATH=/app/src web pdm run python -m skriptoteket.cli &lt;command&gt;&quot;
</code></pre>
<h3 id="container-wont-start">Container Won't Start</h3>
<pre><code class="language-bash"># Check logs for errors
ssh hemma &quot;sudo docker logs skriptoteket-web 2&gt;&amp;1 | tail -50&quot;

# Check if port is in use
ssh hemma &quot;lsof -i :8000&quot;
</code></pre>
<h3 id="dns-not-resolving">DNS Not Resolving</h3>
<pre><code class="language-bash"># Check DDNS status
ssh hemma &quot;sudo systemctl status ddclient&quot;

# Force DDNS update
ssh hemma &quot;ddclient -force&quot;

# Check external IP
ssh hemma &quot;curl -s ifconfig.me&quot;

# Verify DNS at nameserver
dig +short skriptoteket.hule.education @pdns1.registrar-servers.com
</code></pre>
<h3 id="disk-space">Disk Space</h3>
<pre><code class="language-bash"># Check disk usage
ssh hemma &quot;df -h&quot;

# Docker disk usage
ssh hemma &quot;sudo docker system df&quot;

# Clean up unused Docker resources
ssh hemma &quot;sudo docker system prune -f&quot;

# Prune old artifact directories
# (includes platform-only LLM captures under /app/.artifacts/llm-captures/)
ssh hemma &quot;cd ~/apps/skriptoteket &amp;&amp; sudo docker compose -f compose.prod.yaml exec -T -e PYTHONPATH=/app/src web pdm run python -m skriptoteket.cli prune-artifacts&quot;
</code></pre>
          </section>
          <footer>
            Document: <strong>RUN-home-server</strong> — “Runbook: Home Server Operations” — Updated <strong>2026-01-12</strong>.
          </footer>
        </main>
      </div>
    </div>
  </div>
</body>
</html>
