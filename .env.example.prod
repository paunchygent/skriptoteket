# Production environment variables for home server deployment
# Copy to .env and fill in actual values

# Database (shared PostgreSQL on hule-network)
SKRIPTOTEKET_DB_PASSWORD=change-me

# Application secrets
SECRET_KEY=generate-with-python-secrets-token-urlsafe-32

# Observability (HuleEdu-compatible structlog)
SERVICE_NAME=skriptoteket
LOG_LEVEL=INFO
LOG_FORMAT=json

# Health checks
# Include SMTP dependency in /healthz (only applies when EMAIL_PROVIDER=smtp).
HEALTHZ_SMTP_CHECK_ENABLED=true

# Platform-only debug capture (OFF by default; see ADR-0051)
# When enabled, writes sensitive captures under `ARTIFACTS_ROOT/llm-captures/` (model output + tool code).
LLM_CAPTURE_ON_ERROR_ENABLED=false

# Bootstrap superuser (prod provisioning / UI smokes)
BOOTSTRAP_SUPERUSER_EMAIL=superuser@skriptoteket.hule.education
BOOTSTRAP_SUPERUSER_PASSWORD=change-me

# Email (SMTP)
# Note: keep each EMAIL_* key only once (duplicates are confusing; last one wins).
EMAIL_PROVIDER=smtp
EMAIL_SMTP_HOST=mail.privateemail.com
EMAIL_SMTP_PORT=587
EMAIL_SMTP_USERNAME=change-me
EMAIL_SMTP_PASSWORD=change-me
EMAIL_SMTP_USE_TLS=true
EMAIL_SMTP_TIMEOUT=30
EMAIL_DEFAULT_FROM_EMAIL=noreply@hule.education
EMAIL_DEFAULT_FROM_NAME=Skriptoteket
EMAIL_VERIFICATION_BASE_URL=https://skriptoteket.hule.education

# AI / LLM (llama-server OpenAI-compatible)
# Note: on Linux you may need the Docker bridge gateway IP instead of host.docker.internal.
LLM_COMPLETION_ENABLED=true
LLM_COMPLETION_BASE_URL=http://172.18.0.1:8082
LLM_COMPLETION_MODEL=Devstral-Small-2-24B
LLM_COMPLETION_TEMPLATE_ID=inline_completion_v1
OPENAI_LLM_COMPLETION_API_KEY=change-me
LLM_CHAT_ENABLED=true
LLM_CHAT_BASE_URL=http://172.18.0.1:8082
LLM_CHAT_MODEL=Devstral-Small-2-24B
LLM_CHAT_TEMPLATE_ID=editor_chat_v1
OPENAI_LLM_CHAT_API_KEY=change-me
LLM_CHAT_OPS_ENABLED=true
LLM_CHAT_OPS_BASE_URL=http://172.18.0.1:8082
LLM_CHAT_OPS_MODEL=Devstral-Small-2-24B
LLM_CHAT_OPS_TEMPLATE_ID=editor_chat_ops_v1
OPENAI_LLM_CHAT_OPS_API_KEY=change-me

# Chat/chat-ops failover (opt-in; used only when `allow_remote_fallback=true` in requests)
#LLM_CHAT_FALLBACK_BASE_URL=https://api.openai.com
#LLM_CHAT_FALLBACK_MODEL=gpt-5.2
#LLM_CHAT_FALLBACK_REASONING_EFFORT=low
#LLM_CHAT_OPS_FALLBACK_BASE_URL=https://api.openai.com
#LLM_CHAT_OPS_FALLBACK_MODEL=gpt-5.2
#LLM_CHAT_OPS_FALLBACK_REASONING_EFFORT=low
#LLM_CHAT_FAILOVER_PRIMARY_MAX_INFLIGHT=2
#LLM_CHAT_FAILOVER_BREAKER_FAILURE_THRESHOLD=2
#LLM_CHAT_FAILOVER_BREAKER_WINDOW_SECONDS=30
#LLM_CHAT_FAILOVER_BREAKER_COOLDOWN_SECONDS=90
#LLM_CHAT_FAILOVER_STICKY_TTL_SECONDS=600

# OpenAI/OpenRouter prompt caching + provider headers (optional; GPT-5-2 family)
#LLM_COMPLETION_PROMPT_CACHE_RETENTION=24h
#LLM_COMPLETION_PROMPT_CACHE_KEY=skriptoteket:completion
#LLM_COMPLETION_EXTRA_HEADERS={"HTTP-Referer":"https://skriptoteket.hule.education","X-Title":"Skriptoteket"}
#LLM_CHAT_PROMPT_CACHE_RETENTION=24h
#LLM_CHAT_PROMPT_CACHE_KEY=skriptoteket:chat
#LLM_CHAT_EXTRA_HEADERS={"HTTP-Referer":"https://skriptoteket.hule.education","X-Title":"Skriptoteket"}
#LLM_CHAT_OPS_PROMPT_CACHE_RETENTION=24h
#LLM_CHAT_OPS_PROMPT_CACHE_KEY=skriptoteket:chat_ops
#LLM_CHAT_OPS_EXTRA_HEADERS={"HTTP-Referer":"https://skriptoteket.hule.education","X-Title":"Skriptoteket"}

# Observability stack (compose.observability.yaml)
GRAFANA_ADMIN_PASSWORD=change-me
PROMETHEUS_BASIC_AUTH_PASSWORD=change-me
JAEGER_BASIC_AUTH_PASSWORD=change-me
